\documentclass[12pt, a4paper]{article}
\usepackage[margin=2.5cm]{geometry}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{parskip}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[colorlinks,linkcolor=blue,citecolor=blue]{hyperref}

\graphicspath{{./images/}}

\title{Week 4--5 Progress Report: Methods, Data, and Implementation}
\author{Farooq Mahmud}
\date{\today}

\begin{document}
\maketitle
\tableofcontents
\clearpage

%=============================================================================
\section{Project Goal and Research Question}
%=============================================================================

\subsection{Goal}

The goal of this capstone project is to develop and evaluate forecasting methods for daily average Uber trip duration in New York City. This capstone compares an ARIMA approach with an LSTM model on the same dataset \cite{nyctlc2024}. The aim is to produce a 14-day forecast from each method and to assess both using sMAPE and MASE metrics \cite{hyndman2006,prabhat2024}.

\subsection{Research Question}

How do ARIMA and LSTM compare for 14-day forecasting of daily average Uber trip duration in New York City when evaluated on sMAPE and MASE?

%=============================================================================
\section{Expanded Methods}
%=============================================================================

\subsection{Problem Definition}

This capstone predicts daily average Uber trip duration (in minutes) in New York City. The target variable is the mean trip duration per day, aggregated from high-volume for-hire vehicle (FHV) trip records \cite{nyctlc2024}. The inputs are a univariate time series of 366 (2024 was a leap year) daily observations. The outputs are (1) a 14-day point forecast of average trip duration from each method (ARIMA and LSTM), and (2) for comparison, the same horizon evaluated with sMAPE and MASE \cite{hyndman2006,prabhat2024} over a common 14-day period.

\subsection{Data Description}

The data are daily average Uber trip duration (in minutes) for New York City in 2024, derived from the New York City Taxi and Limousine Commission (TLC) High-Volume FHV trip record data \cite{nyctlc2024}. Key variables are \texttt{pickup\_date} and \texttt{avg\_duration\_min}. The preprocessed time-series has 366 daily observations. Preprocessing is done via PySpark aggregation to daily averages.

\subsection{Preprocessing Plan} \label{sec:preprocessing}

The following preprocessing is common to both modeling methods and produces the single daily time series (\texttt{pickup\_date}, \texttt{avg\_duration\_min}) that both ARIMA and LSTM use. It was applied to the NYC TLC High-Volume FHV trip record data \cite{nyctlc2024}. Preprocessing is necessary because the original dataset contains over 200 million trip records, of which about 179 million are Uber trip records. Outliers and invalid or nonsensical data are also removed resulting in a final total of about 159 million rows. These rows are converted to a CSV file representing the time-series. The CSV contains the 366 daily average trip duration (minutes) for 2024, produced by aggregating trip-level records (via PySpark) to one row per day.

\begin{enumerate}
\item \textbf{Filter to Uber trips.} Retain only records with \texttt{hvfhs\_license\_num} equal to \texttt{HV0003} (Uber).
\item \textbf{Derived columns.} Compute trip duration in minutes (\texttt{trip\_time}/60) and average speed in mph (\texttt{trip\_miles}/(\texttt{trip\_time}/3600)).
\item \textbf{Basic cleaning.} Remove trips with zero or negative duration, distance, or speed. Remove obvious outliers: trip duration outside 1--120 minutes, trip distance outside 0.1--100 miles, average speed outside 1--80 mph.
\item \textbf{IQR-based outlier removal.} For \texttt{trip\_duration\_min}, \texttt{trip\_miles}, and \texttt{avg\_speed\_mph}, compute the interquartile range (IQR) and drop trips above $Q_3 + 1.5 \times \text{IQR}$ for each variable.
\item \textbf{Aggregation.} Group by \texttt{pickup\_date} (date of \texttt{pickup\_datetime}), compute the mean trip duration per day (\texttt{avg\_duration\_min}), order by date, and round the average. The result is one row per day (366 days for 2024).
\item \textbf{Loading for modeling.} Both methods use the same CSV file containing the 366 data points. No additional shared preprocessing (e.g., scaling or differencing) is applied before method-specific steps. ARIMA may use differencing in the model, and LSTM uses train/validation/test splits and scaling within its pipeline.
\end{enumerate}

\subsection{Modeling Plan}

\paragraph{ARIMA.}
The first forecasting method is an ARIMA model fitted to the time-series. Stationarity is assessed using the Augmented Dickey--Fuller test. Candidate ARIMA models are compared using AIC and BIC \cite{forecast_auto_arima}. residual diagnostics (Ljung--Box test, ACF of residuals) are used to select the final specification. The chosen model is ARIMA(3,1,2): three autoregressive terms, one order of differencing, and two moving-average terms. A 14-day point forecast is produced with 80\% and 95\% prediction intervals. The narrative presents this methodology via relevant excerpts; the prior report is not cited.

\paragraph{LSTM.}
The second method is a long short-term memory (LSTM) network implemented in R with the \texttt{keras} package \cite{keras_r}, following time-series forecasting patterns \cite{keras_timeseries}. The series is split chronologically into train, validation, and test (e.g., last 14 days held out as test). Training data are scaled (e.g., min-max) and used to build sliding-window sequences of fixed length (e.g., 21 days) to predict the next day. The model has one LSTM layer (e.g., 32 units), dropout for regularization, and a dense output. It is trained with early stopping on validation loss. The 14-day forecast is produced recursively: predict one step ahead, append to the input sequence, and repeat. This keeps the LSTM pipeline comparable to ARIMA in horizon and evaluation.

\paragraph{Comparison.}
Both methods are evaluated on the same 14-day horizon and the same test period. Metrics are sMAPE and MASE \cite{hyndman2006,prabhat2024}. Results are reported in a single table (ARIMA vs LSTM: sMAPE, MASE) and one figure (actual vs both forecasts over the 14 days).

\subsection{Evaluation Plan}

Metrics are sMAPE and MASE over the 14-day forecast \cite{hyndman2006,prabhat2024}. MASE is scaled by the mean absolute error of a naive one-step forecast on the training data \cite{hyndman2006}. The same test period is used for both methods. Results are presented in a table (ARIMA vs LSTM: sMAPE, MASE) and a figure (actual vs both forecasts over the 14 days).

%=============================================================================
\section{Dataset and Access}
%=============================================================================

\subsection{Source}

The primary data source used in the capstone is the CSV file explained in ~\ref{sec:preprocessing}.

\subsection{Access and Loading}

The dataset is loaded in R via \texttt{read.csv()} (see \texttt{code/lstm\_forecast.qmd}). Proof of load: the series has \textbf{366 rows} (one per day in 2024) and \textbf{2 columns}: \texttt{pickup\_date} (Date) and \texttt{avg\_duration\_min} (numeric). There are \textbf{no missing values} in the aggregated series. The CSV is located in the capstone repo (e.g.\ \texttt{code/data/finalproject.csv} or \texttt{docs/hw4-5/data/finalproject.csv}); the same file is used by both ARIMA (in the prior R/Quarto pipeline) and LSTM (\texttt{lstm\_forecast.qmd}).

%=============================================================================
\section{Implementation and Experiments}
%=============================================================================

\subsection{What Was Implemented}

(1)~\textbf{ARIMA:} The 14-day forecast is reproduced using the existing R/Quarto pipeline (ARIMA(3,1,2), \texttt{forecast()} with \texttt{h = 14}). Excerpts of the method and results (forecast table and figure) are included in this report. (2)~\textbf{LSTM:} The pipeline in \texttt{code/lstm\_forecast.qmd} (R/keras) is run to produce a 14-day recursive forecast and to compute sMAPE and MASE on the same test window; it also saves \texttt{lstm\_forecast\_14day.csv} for comparison. (3)~\textbf{Comparison:} A Python script \texttt{code/compare\_forecasts.py} reads the ARIMA and LSTM forecast files and actuals, computes sMAPE and MASE for both methods, and produces a comparison table and a figure (actual vs ARIMA vs LSTM over the 14 days).

\subsection{What Was Tested}

Dataset: \texttt{finalproject.csv} (full 2024, 366 days). For LSTM, the series is split chronologically: the last 14 days are held out as test; the preceding 30 days as validation; the remainder as training. The same 14-day test window is used for evaluation so that ARIMA and LSTM can be compared on the same dates. Target variable: \texttt{avg\_duration\_min} (daily average trip duration in minutes).

\subsection{What Worked and What Did Not}

ARIMA fitting and 14-day forecasting run successfully with the chosen specification. The LSTM pipeline runs end-to-end; early stopping on validation loss is used to limit overfitting. Limitations encountered: (i)~small sample size (366 points) limits LSTM capacity and favors simpler models; (ii)~hyperparameters (sequence length, units, dropout) were chosen pragmatically and could be refined; (iii)~alignment of the 14-day evaluation period between ARIMA and LSTM must be ensured (e.g., both forecasting the same last-14-days window) for a fair comparison.

\subsection{Preliminary Outputs}

ARIMA: 14-day forecast table and plot are included as excerpts in Section~\ref{sec:results-arima}. LSTM: 14-day forecast figure and training/validation loss curve are produced by \texttt{lstm\_forecast.qmd}. Comparison: table (ARIMA vs LSTM sMAPE, MASE) and plot (actual vs both forecasts over the 14 days) are generated by \texttt{compare\_forecasts.py} and included in Section~\ref{sec:results-compare}.

%=============================================================================
\section{Results (Preliminary)}
%=============================================================================

\subsection{ARIMA}\label{sec:results-arima}

The ARIMA(3,1,2) model produces a 14-day point forecast with 80\% and 95\% prediction intervals. Excerpts of the forecast table (dates, point forecast, Lo/Hi 80 and 95) and the forecast plot are included here. [Insert forecast table and figure from the ARIMA pipeline run.]

\subsection{LSTM}

The LSTM model (one layer, 32 units, sequence length 21, dropout 0.2) produces a 14-day recursive forecast. Training and validation loss curves from \texttt{lstm\_forecast.qmd} show convergence; early stopping is used. sMAPE and MASE over the 14-day test window are reported in the comparison table below. [Insert LSTM forecast figure and loss curve from \texttt{lstm\_forecast.qmd}.]

\subsection{Comparison (ARIMA vs LSTM)}\label{sec:results-compare}

Table~\ref{tab:compare} summarizes sMAPE (\%) and MASE for both methods over the same 14-day period. A figure (actual vs ARIMA vs LSTM) illustrates the forecasts.

\begin{table}[ht]
\centering
\caption{Comparison of ARIMA and LSTM on 14-day forecast (sMAPE and MASE). Replace with output from \texttt{compare\_forecasts.py}.}
\label{tab:compare}
\begin{tabular}{lcc}
\toprule
Model & sMAPE (\%) & MASE \\
\midrule
ARIMA & -- & -- \\
LSTM  & -- & -- \\
\bottomrule
\end{tabular}
\end{table}

[Insert comparison figure from \texttt{compare\_forecasts.py}.] Interpretation: [after running both pipelines and the comparison script, state which method performed better on sMAPE and MASE and briefly discuss possible reasons (e.g., ARIMA stability with small data vs LSTM flexibility).]

%=============================================================================
\section{Issues and Limitations}
%=============================================================================

Limitations include: (i)~\textbf{Small sample size}---366 daily observations is on the small side for deep learning; the LSTM has limited training sequences after the chronological split, which may favor the simpler ARIMA model. (ii)~\textbf{Univariate models}---both methods use only the daily average trip duration; no exogenous regressors (e.g., day-of-week, holidays) are included. (iii)~\textbf{Alignment of evaluation period}---for a fair comparison, ARIMA and LSTM must forecast the same 14-day window (e.g., last 14 days of 2024); if ARIMA was run for a different horizon (e.g., 2025-01-01 onward), the comparison table and figure should use aligned dates. (iv)~Any bugs or data issues encountered during implementation can be noted here.

%=============================================================================
\section{Next Steps}
%=============================================================================

Complete the comparison script run and insert the final comparison table and figure into the report; add the ARIMA 14-day forecast to the comparison if not yet exported. If more years of NYC TLC data become available, extend the series to improve LSTM training. Refine LSTM hyperparameters (sequence length, units, dropout) and consider cross-validation. Finalize the report (replace placeholders with actual tables and figures), export to PDF, and submit.

%=============================================================================
\bibliographystyle{plain}
\bibliography{week4_5_report}
%=============================================================================
\end{document}
